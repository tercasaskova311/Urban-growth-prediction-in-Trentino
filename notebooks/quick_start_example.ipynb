{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Growth Prediction in Trentino - Quick Start Example\n",
    "\n",
    "This notebook demonstrates the basic usage of the urban growth prediction framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '../src'))\n",
    "\n",
    "from src.utils import load_config\n",
    "from src.signal_processing import SpatioTemporalProcessor\n",
    "from src.models import UrbanGrowthPredictor, create_synthetic_dataset\n",
    "from src.utils.visualization import plot_confusion_matrix, plot_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Signal Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a processor\n",
    "processor = SpatioTemporalProcessor(tile_size=1000, overlap=100)\n",
    "\n",
    "# Example time series (simulating NDBI over 5 years)\n",
    "time_series = np.array([0.1, 0.12, 0.15, 0.18, 0.22, 0.25])\n",
    "timestamps = np.array([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "# Detect trend\n",
    "trend = processor.detect_trend(time_series, timestamps, method='linear_regression')\n",
    "print(\"Trend Analysis:\")\n",
    "print(f\"  Slope: {trend['slope']:.4f}\")\n",
    "print(f\"  RÂ²: {trend['r_squared']:.4f}\")\n",
    "print(f\"  P-value: {trend['p_value']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize trend\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamps, time_series, 'o-', label='Data', linewidth=2)\n",
    "trend_line = trend['slope'] * timestamps + trend['intercept']\n",
    "plt.plot(timestamps, trend_line, 'r--', label=f\"Trend (slope={trend['slope']:.4f})\", linewidth=2)\n",
    "plt.xlabel('Time (years)')\n",
    "plt.ylabel('NDBI')\n",
    "plt.title('Urban Growth Trend Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Change Point Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with change point\n",
    "time_series_with_change = np.array([0.1, 0.11, 0.12, 0.11, 0.25, 0.27, 0.28, 0.29])\n",
    "timestamps_change = np.arange(len(time_series_with_change))\n",
    "\n",
    "# Detect change points\n",
    "change_points = processor.detect_change_points(time_series_with_change, method='cusum')\n",
    "print(f\"Detected change points at indices: {change_points}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamps_change, time_series_with_change, 'o-', linewidth=2)\n",
    "for cp in change_points:\n",
    "    plt.axvline(x=cp, color='r', linestyle='--', alpha=0.5, label='Change Point')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Change Point Detection')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from time series\n",
    "features = processor.extract_features(time_series, timestamps)\n",
    "\n",
    "print(\"Extracted Features:\")\n",
    "for key, value in features.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset for demonstration\n",
    "print(\"Creating synthetic dataset...\")\n",
    "df, labels = create_synthetic_dataset(n_samples=1000)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {df.columns.tolist()}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(f\"  Shrink (0): {(labels == 0).sum()}\")\n",
    "print(f\"  Stable (1): {(labels == 1).sum()}\")\n",
    "print(f\"  Grow (2): {(labels == 2).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor\n",
    "predictor = UrbanGrowthPredictor(model_type='gradient_boosting')\n",
    "\n",
    "# Define features to use\n",
    "feature_columns = ['ndvi_trend', 'ndbi_trend', 'building_density', \n",
    "                  'road_density', 'mobility_index']\n",
    "\n",
    "# Prepare features\n",
    "X, feature_names = predictor.prepare_features(df, feature_columns)\n",
    "\n",
    "# Train model\n",
    "print(\"\\nTraining model...\")\n",
    "results = predictor.train(X, labels, feature_names=feature_names,\n",
    "                         n_estimators=100, max_depth=6, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "plot_confusion_matrix(results['confusion_matrix'], predictor.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data for prediction\n",
    "test_df, _ = create_synthetic_dataset(n_samples=100)\n",
    "X_test, _ = predictor.prepare_features(test_df, feature_columns)\n",
    "\n",
    "# Make predictions\n",
    "predictions = predictor.predict(X_test)\n",
    "probabilities = predictor.predict_proba(X_test)\n",
    "\n",
    "# Display summary\n",
    "print(\"Prediction Summary:\")\n",
    "for i, class_name in enumerate(predictor.class_names):\n",
    "    count = (predictions == i).sum()\n",
    "    percentage = count / len(predictions) * 100\n",
    "    print(f\"  {class_name.capitalize()}: {count} tiles ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "prediction_counts = []\n",
    "for i in range(len(predictor.class_names)):\n",
    "    prediction_counts.append((predictions == i).sum())\n",
    "\n",
    "plt.bar(predictor.class_names, prediction_counts, color=['red', 'gray', 'green'])\n",
    "plt.xlabel('Prediction Class')\n",
    "plt.ylabel('Number of Tiles')\n",
    "plt.title('Distribution of Urban Growth Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Signal processing techniques for temporal analysis\n",
    "- Trend detection in time series\n",
    "- Change point detection\n",
    "- Feature extraction from spatio-temporal signals\n",
    "- Training a machine learning model for urban growth prediction\n",
    "- Making predictions on new data\n",
    "\n",
    "For real-world applications, you would:\n",
    "1. Acquire actual Sentinel-2 imagery from Google Earth Engine\n",
    "2. Download OpenStreetMap data for the region\n",
    "3. Integrate mobility data\n",
    "4. Process the data through the full pipeline\n",
    "5. Generate spatial predictions and visualizations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
